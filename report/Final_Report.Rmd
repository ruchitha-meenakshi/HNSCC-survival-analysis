---
title: "Prognostic Modeling of Overall Survival in HNSCC"
subtitle: "A Comparative Analysis of Traditional Statistics vs. Machine Learning"
author: "Ruchitha Uppuluri"
output:
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
    fig_caption: true
    highlight: tango
fontsize: 11pt
geometry: margin=1in
---

```{r setup, include=FALSE}
# Global chunk options for a clean report
knitr::opts_chunk$set(
  echo = FALSE, 
  warning = FALSE, 
  message = FALSE, 
  fig.align = 'center', 
  out.width = "85%"
)
# Load libraries
library(here)
library(tidyverse)
library(survival)
library(survminer)
library(glmnet)
library(caret)
library(randomForestSRC)
library(xgboost)
library(knitr)
library(kableExtra)
```

```{r load-scripts, include=FALSE}
# Load analysis scripts
suppressMessages({
  source(here("scripts", "01_data_loading_cleaning.R"))
  source(here("scripts", "02_exploratory_data_analysis.R"))
  source(here("scripts", "03_statistical_modeling.R"))
  source(here("scripts", "04_machine_learning_rf_modeling.R"))
  source(here("scripts", "05_ml_feature_log_xgb_modeling.R"))
  source(here("scripts", "06_survival_forest_coxnet.R"))
  source(here("scripts", "07_results_visualisation_interpretation.R"))
})

clinical_data <- readRDS(here("data", "cleaned_clinical_data.rds"))
```

# Project Overview
Head and Neck Squamous Cell Carcinoma (HNSCC) presents a significant clinical challenge due to variable survival rates across tumor stages. This project evaluates the efficacy of modern Machine Learning approaches—specifically Random Survival Forests (RSF)—against traditional Cox Proportional Hazards models to improve prognostic accuracy.

## Key Findings:

- **Random Survival Forests (RSF)** outperformed traditional models, achieving a Concordance Index (C-Index) of **0.74**.

- **Tumor Stage IVC** was identified as the single strongest predictor of mortality.

- **Time-to-Event models** proved superior to binary classification (2-year survival), highlighting the critical importance of handling censored data in clinical analytics.

# Data & Methodology
Using clinical data from **The Cancer Genome Atlas (TCGA)** ($N=`r nrow(clinical_data)`$), we conducted a comparative analysis using three distinct modeling approaches:
  1. **Traditional Statistics:** Kaplan-Meier estimation and Cox Proportional Hazards.
  2. **Binary Machine Learning:** Random Forest, Logistic Regression and XGBoost (predicting survival > 24 months).
  3. **Survival Machine Learning:** Random Survival Forests (RSF) and Penalized Cox Regression (CoxNet).

#  Exploratory Data Analysis

## Demographics
The patient cohort exhibits a typical age distribution for HNSCC onset, with a median age of `r median(clinical_data$age, na.rm=TRUE)` years. The gender distribution reflects known epidemiological prevalence (Male > Female), as shown below.

```{r, fig.cap="Patient Age Distribution", out.width="49%", fig.show='hold'}
# Show Age and Gender side-by-side for a cleaner layout
knitr::include_graphics(here("outputs", "plots", "eda", "eda_age_distribution.png"))
knitr::include_graphics(here("outputs", "plots", "eda", "eda_gender_distribution.png"))
```

## Clinical Characteristics
A significant portion of the dataset presents with advanced-stage disease (Stage IVA), which strongly influences the modeling strategy.

```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "eda", "eda_stage_distribution.png"))
```

```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "eda", "eda_survival_status.png"))
```

# Traditional Survival Modeling
We established a baseline using Kaplan-Meier estimators and Cox Proportional Hazards models.

## Survival by Tumor Stage
There is significant prognostic separation between early and late-stage disease ($p < 0.0001$), validating the clinical data quality.
```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "survival", "km_survival_by_stage.png"))
```

## Survival by Gender
Gender differences in survival were observed, though less pronounced than tumor stage.
```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "survival", "km_survival_by_gender.png"))
```

# Machine Learning Models (Binary Classification)
We initially modeled the problem as a binary classification task (Survival > 24 Months). However, this approach discards valuable time-to-event information for censored patients.

## Random Forest Classifier
The standard Random Forest achieved moderate performance but struggled with the class imbalance inherent in the dataset.

```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "ml", "rf_cv_roc_curve.png"))
```

## Logistic Regression with L1 Regularization
Logistic regression with Lasso regularization was implemented to handle potential multicollinearity, but predictive power remained comparable to the Random Forest
```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "ml", "logistic_roc_curve.png"))
```

## XGBoost Classifier
XGBoost results were similar to other binary classifiers, suggesting that the limitation lies in the binary formulation of the problem rather than the algorithm choice.
```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "ml", "xgb_roc_curve.png"))
```

# Advanced Survival Machine Learning
To address the limitations of binary classification, we implemented models capable of handling censored time-to-event data directly.

## Random Survival Forest (RSF)
The RSF model achieved the highest predictive performance. The Variable Importance (VIMP) plot below highlights Tumor Stage and Age as the dominant predictors.
```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "rsf", "rsf_variable_importance.png"))
```

## Penalized Cox Regression (CoxNet)
L1-regularization (Lasso) was used to perform feature selection within the Cox framework.
```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "survival", "coxnet_variable_importance.png"))
```

# Clinical Utility: Subgroup Predictions
Using the CoxNet model, we generated predicted survival curves for hypothetical patient profiles to demonstrate clinical utility.
```{r, out.width="80%"}
subgroup_table <- read_csv(here("outputs", "tables","coxnet_subgroup_medians.csv"))
knitr::kable(subgroup_table, 
             caption = "Predicted Median Survival by Subgroup (CoxNet)",
             digits = 1,
             booktabs = TRUE)
```

```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "survival","coxnet_predicted_survival_age.png"))
```

```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "survival", "coxnet_predicted_survival_gender.png"))
```

# Model Performance Comparison
- The table and chart below summarize the performance across all modeling techniques. 
- The Random Survival Forest demonstrated superior discrimination compared to both traditional Cox models and binary classifiers.

```{r}
# Load the results table
results_table <- read_csv(here("outputs", "tables", "final_model_performance_summary.csv"))

knitr::kable(results_table, 
             caption = "Performance Benchmarking: C-Index (Survival Models) vs AUC (Binary Classifiers)",
             digits = 3,
             booktabs = TRUE)
```

```{r, out.width="80%"}
knitr::include_graphics(here("outputs", "plots", "final_model_comparison_plot.png"))
```

# Conclusion
This analysis demonstrates that Time-to-Event Machine Learning models (RSF) provide a quantifiable improvement over traditional statistical methods for HNSCC prognosis.

## Strategic Implications:

  1. **Methodology:** Binary classification proved insufficient for this clinical dataset due to heavy censorship and class imbalance. Survival Forests should be considered the standard for high-dimensional clinical survival data.

  2. **Clinical:** While Tumor Stage remains the primary risk factor, Age and Primary Site contribute non-linear risk effects that are captured by ensemble methods but missed by linear Cox models.

  3. **Future Work:** Integrating genomic data (e.g., TP53 mutation status) with this clinical RSF model could further enhance predictive precision.
